model_name_or_path: models/ChatGLM3
template: chatglm3

### method
stage: sft
#do_predict: true
#finetuning_type: lora

### dataset
eval_dataset: ed_tst 
template: llama3
cutoff_len: 1024
max_samples: 50
overwrite_cache: true
preprocessing_num_workers: 16

### output
#output_dir: saves/llama3-8b/lora/predict
#overwrite_output_dir: true

### eval
#per_device_eval_batch_size: 1
#predict_with_generate: true
#ddp_timeout: 180000000
